{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "mport numpy\nimport tensorflow #open source used for both ML and DL for computation\nfrom tensorflow.keras.datasets import mnist #mnist dataset\nfrom tensorflow.keras.models import Sequential #it is a plain stack of layers\nfrom tensorflow.keras import layers #A Layer consists of a tensor- in tensor-out computat ion funct ion\nfrom tensorflow.keras.layers import Dense, Flatten #Dense-Dense Layer is the regular deeply connected r\n#faltten -used fot flattening the input or change the dimension\nfrom tensorflowHandwritten_Digit_Recognition.ipynb.keras.layers import Conv2D #onvoLutiona l Layer\nfrom keras.optimizers import Adam #opt imizer\nfrom keras. utils import np_utils #used for one-hot encoding\nimport matplotlib.pyplot as plt   #used for data visualization\n(x_train, y_train), (x_test, y_test)=mnist.load_data () #splitting the mnist data into train and test\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 1s 0us/step\nprint (x_train.shape)  #shape is used for give the dimens ion values #60000-rows 28x28-pixels\nprint (x_test.shape)\n(60000, 28, 28)\n(10000, 28, 28)\nx_train[0]\narray([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)\nplt.imshow(x_train[6000])     #ploting the index=image\n\nnumpy.argmax(y_train[6000])\n0\n#Reshaping to format which CNN expects (batch, height, width, channels)\nx_train=x_train.reshape (60000, 28, 28, 1).astype('float32')\nx_test=x_test.reshape (10000, 28, 28, 1).astype ('float32')\nnumber_of_classes = 10  #storing the no of classes in a variable\ny_train = np_utils.to_categorical (y_train, number_of_classes) #converts the output in binary format\ny_test = np_utils.to_categorical (y_test, number_of_classes)\n#create model\nmodel=Sequential ()\n#adding modeL Layer\nmodel.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation = 'relu'))\n#flatten the dimension of the image\nmodel.add(Flatten())\n#output layer with 10 neurons\nmodel.add(Dense(number_of_classes,activation = 'softmax'))\n#Compile model\nmodel.compile(loss= 'categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\nx_train = numpy.asarray(x_train)\ny_train = numpy.asarray(y_train)\n#fit the model\nmodel.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)\nEpoch 1/5\n1875/1875 [==============================] - 212s 109ms/step - loss: 0.2343 - accuracy: 0.9515 - val_loss: 0.0973 - val_accuracy: 0.9723\nEpoch 2/5\n1875/1875 [==============================] - 219s 117ms/step - loss: 0.0666 - accuracy: 0.9799 - val_loss: 0.1110 - val_accuracy: 0.9663\nEpoch 3/5\n1875/1875 [==============================] - 183s 97ms/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 0.0943 - val_accuracy: 0.9750\nEpoch 4/5\n1875/1875 [==============================] - 160s 85ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.0959 - val_accuracy: 0.9747\nEpoch 5/5\n1875/1875 [==============================] - 154s 82ms/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.1019 - val_accuracy: 0.9756\n# Final evaluation of the model\nmetrics = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Metrics (Test loss &Test Accuracy) : \")\nprint(metrics)\nMetrics (Test loss &Test Accuracy) : \n[0.10187830030918121, 0.975600004196167]\nprediction=model.predict(x_test[6000:6001])\nprint(prediction)\n1/1 [==============================] - 6s 6s/step\n[[1.2413231e-13 4.0926510e-15 2.0204852e-13 8.5849187e-04 1.7845260e-04\n  5.4279004e-05 1.4596199e-14 2.1835026e-06 1.0488740e-05 9.9889612e-01]]\nimport numpy as np\nprint(np.argmax(prediction, axis=1)) #printing our Labels from first 4 images\n[9]\nnp.argmax(y_test[6000:6001]) #printing the actual labels\n9\n# Save the model\nmodel.save('mnistCNN.h5')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}